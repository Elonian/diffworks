# Diffusion Works

### Theoretical Works

How to Train Your Energy-Based Models - https://arxiv.org/pdf/2101.03288

High-Resolution Image Synthesis with Latent Diffusion Models - https://arxiv.org/abs/2112.10752

Adding Conditional Control to Text-to-Image Diffusion Models - https://arxiv.org/pdf/2302.05543

DreamBooth: Fine Tuning Text-to-Image Diffusion Models
for Subject-Driven Generation - https://arxiv.org/pdf/2208.12242

InstantBooth: Personalized Text-to-Image Generation without Test-Time
Finetuning - https://arxiv.org/pdf/2304.03411

Video Diffusion Models - https://arxiv.org/pdf/2204.03458

GLIDE: Towards Photorealistic Image Generation and Editing with
Text-Guided Diffusion Models - https://arxiv.org/pdf/2112.10741

SDEdit: Guided Image Synthesis and Editing with Stochastic Differential Equations - https://arxiv.org/pdf/2108.01073



## Video Pipelines - Pretrained Text to Video Models
TokenFlow: Consistent Diffusion Features for Consistent Video Editing - https://arxiv.org/pdf/2307.10373

Rerender A Video: Zero-Shot TextGuided Video-to-Video Translation. - https://arxiv.org/pdf/2306.07954

Text2Video-Zero:
Text-to-Image Diffusion Models are Zero-Shot Video Generators - https://arxiv.org/pdf/2303.13439

## Video Piplines - Finetuning and temporal attention
MagicEdit: HighFidelity and Temporally Coherent Video Editing. - https://arxiv.org/pdf/2308.14749

Video-P2P: Video Editing with
Cross-attention Control. - https://arxiv.org/pdf/2303.04761

Edit-A-Video:
Single Video Editing with Object-Aware Consistency. - https://arxiv.org/pdf/2303.07945

ControlVideo: Conditional Control for One-shot Text-driven Video Editing and Beyond - https://arxiv.org/pdf/2305.17098

Tune-A-Video: One-Shot Tuning of Image Diffusion Models for Text-to-Video Generation - https://arxiv.org/pdf/2212.11565

##

Pix2Video: Video Editing using Image
Diffusion. - https://arxiv.org/pdf/2303.12688

